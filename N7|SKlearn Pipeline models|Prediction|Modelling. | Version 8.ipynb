{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/darshanprabhu09/n7-sklearn-pipeline-models-prediction-modelling?scriptVersionId=135422350\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"6469a47f","metadata":{"papermill":{"duration":0.010516,"end_time":"2023-07-01T12:06:44.034038","exception":false,"start_time":"2023-07-01T12:06:44.023522","status":"completed"},"tags":[]},"source":["# <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: #FF4500; border-bottom: 8px solid WHITE\" > TABLE OF CONTENTS<br><div>  \n","    \n","* [1 - DATA DESCRIPTION](#1)\n","    \n","* [2 - IMORTING LIBRARIES](#2)\n","    \n","* [3 - DATA COLLECTION & PREPARATION](#3)\n","    \n","* [4 - EXPLORATORY DATA ANALYSIS](#4)\n","    * [4.1 - TRAINING DATA](#4.1)\n","    * [4.2 - TESTING DATA](#4.2)\n","    * [4.3 - CONVERSION TO NUMPY ARRAY](#4.3)\n","    * [4.4 - SCALING](#4.4)\n","    \n","    \n","* [5 - MODEL BUILDING](#5)\n","   * [5.1 - LINEAR REGRESSION](#5.1)\n","      * [OUTPUT](#5.1.1)\n","      * [MEAN ABSOLUTE ERROR](#5.1.2)\n","      * [MODEL FITTING](#5.1.3)\n","    \n","      * [6 - PREDICTION](#6)\n","    \n","      * [7 - EVALUATION FOR LINEAR REGRESSION MODEL](#7)\n","    \n","   * [5.2 - KNN MODEL](#5.2)\n","      * [6.2 - EVALUATION](#6.2)\n","    \n","   \n","   * [5.3 - RANDOM FOREST REGRESSION](#5.3)\n","     * [5.3.1 - PREDICTION](#5.3.1)\n","    \n","* [8 - CONCLUSION](#8)\n","    "]},{"cell_type":"markdown","id":"2801345f","metadata":{"papermill":{"duration":0.010527,"end_time":"2023-07-01T12:06:44.054701","exception":false,"start_time":"2023-07-01T12:06:44.044174","status":"completed"},"tags":[]},"source":["# <a id=\"1\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >1 -    DATA DESCRIPTION : \n"," <br><div>\n","\n","\n","\n","**The given dataset provides information on various attributes related to housing in different neighborhoods of California. Here is a partial description of the dataset:**\n","\n","- **longitude**: The longitude coordinates of the housing location.\n","\n","- **latitude**: The latitude coordinates of the housing location.\n","\n","- **housing_median_age**: The median age of houses in a specific neighborhood.\n","\n","- **total_rooms**: The total number of rooms in a housing unit.\n","\n","- **total_bedrooms**: The total number of bedrooms in a housing unit.\n","\n","- **population**: The population count in a specific neighborhood.\n","\n","- **households**: The number of households in a specific neighborhood.\n","\n","- **median_income**: The median income of households in a specific neighborhood.\n","\n","- **median_house_value**: The median value of houses in a specific neighborhood.\n","\n","- **ocean_proximity**: The proximity of a housing unit to the ocean.\n","\n","The dataset contains additional information such as labels and counts for different ranges of longitude, latitude, housing_median_age, total_rooms, total_bedrooms, population, households, median_income, and median_house_value.\n"]},{"cell_type":"markdown","id":"aaca225a","metadata":{"papermill":{"duration":0.010618,"end_time":"2023-07-01T12:06:44.075518","exception":false,"start_time":"2023-07-01T12:06:44.0649","status":"completed"},"tags":[]},"source":["<p style=\"padding: 10px; background-color: #000000; margin: 0; color: #FF4500; font-family: New Times Roman; font-size: 135%; text-align: left; border-radius: 5px; overflow: hidden; font-weight: 500;\">\n","  Steps to be used to build a Machine Learning Model : \n","</p>\n","\n","\n","<style>\n","    body {\n","        font-family: Arial, sans-serif;\n","        margin: 20px;\n","        background-color: #f5f5f5;\n","    }\n","\n","    h2 {\n","        text-align: center;\n","        color: #333;\n","    }\n","\n","    ol {\n","        margin-left: 30px;\n","    }\n","\n","    li {\n","        margin-bottom: 15px;\n","    }\n","\n","    h3 {\n","        color: #555;\n","    }\n","\n","    p {\n","        margin-bottom: 10px;\n","    }\n","\n","    code {\n","        background-color: #f8f8f8;\n","        padding: 2px 4px;\n","        font-family: 'Courier New', monospace;\n","        font-size: 14px;\n","    }\n","</style>\n","\n","## 7 Steps to Building a SKlearn Pipeline Model\n","\n","1. **Step 1: Import the necessary libraries**\n","   \n","   Import the required libraries such as `sklearn.pipeline` and the desired SKlearn model(s) for your pipeline.\n","\n","2. **Step 2: Prepare the data**\n","   \n","   Load and preprocess your data using techniques like data cleaning, feature engineering, and feature scaling also define the data into \"Training data\" , \"Testing Data\" the split generally to be used is (80% for training and 20% for the purpose of Testing).\n","\n","3. **Step 3: Define the pipeline**\n","   \n","   Create an instance of the `Pipeline` class and define the sequence of transformations and the final estimator.\n","\n","4. **Step 4: Specify preprocessing steps**\n","   \n","   For each step in the pipeline, specify the preprocessing operation, such as feature scaling or encoding categorical variables.\n","\n","5. **Step 5: Fit the pipeline**\n","   \n","   Fit the pipeline on your training data, which applies all the specified transformations and trains the final estimator.\n","\n","6. **Step 6: Evaluate the model**\n","   \n","   Assess the performance of your model on the test set using appropriate evaluation metrics like accuracy, precision, or mean squared error.\n","\n","7. **Step 7: Use the model for predictions**\n","   \n","   Once the model is trained and evaluated, you can use it to make predictions on new, unseen data by applying the pipeline transformations and using the final estimator's `predict` method.\n"]},{"cell_type":"markdown","id":"b5a16c66","metadata":{"papermill":{"duration":0.00954,"end_time":"2023-07-01T12:06:44.094888","exception":false,"start_time":"2023-07-01T12:06:44.085348","status":"completed"},"tags":[]},"source":["# <a id=\"2\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >2 - IMPORTING THE ESSENTIAL LIBRARIES: \n","  <br><div>\n","#### <span style=\"color: #FF4500;\"> The import statement is used to bring in the libraries into your Python program. numpy is typically imported as np, and pandas is commonly imported as pd. These libraries are widely used for data manipulation, analysis, and processing in Python.\n","\n","\n"]},{"cell_type":"code","execution_count":1,"id":"9ee345f7","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:44.116451Z","iopub.status.busy":"2023-07-01T12:06:44.115634Z","iopub.status.idle":"2023-07-01T12:06:45.538474Z","shell.execute_reply":"2023-07-01T12:06:45.536786Z"},"papermill":{"duration":1.436643,"end_time":"2023-07-01T12:06:45.541225","exception":false,"start_time":"2023-07-01T12:06:44.104582","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","import sklearn "]},{"cell_type":"markdown","id":"83042626","metadata":{"papermill":{"duration":0.010079,"end_time":"2023-07-01T12:06:45.561781","exception":false,"start_time":"2023-07-01T12:06:45.551702","status":"completed"},"tags":[]},"source":["# <a id=\"3\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >3 - DATA COLLECTION & PREPARATION.<br><div>\n","#### <span style=\"color: #FF4500;\">We did break data into \"Training set\" and \"Testing set\" for the purpose of training our model and later on for the evaluation of the model.\n"]},{"cell_type":"code","execution_count":2,"id":"885fedba","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.583647Z","iopub.status.busy":"2023-07-01T12:06:45.583286Z","iopub.status.idle":"2023-07-01T12:06:45.659483Z","shell.execute_reply":"2023-07-01T12:06:45.65834Z"},"papermill":{"duration":0.090039,"end_time":"2023-07-01T12:06:45.661942","exception":false,"start_time":"2023-07-01T12:06:45.571903","status":"completed"},"tags":[]},"outputs":[],"source":["test_df = pd.read_csv(\"/kaggle/input/data-of-california-housing-tale-of-train-and-test/california_housing_test.csv\")  #testing dataset\n","train_df = pd.read_csv(\"/kaggle/input/data-of-california-housing-tale-of-train-and-test/california_housing_train.csv\") #training dataset"]},{"cell_type":"markdown","id":"e6e08afa","metadata":{"papermill":{"duration":0.009877,"end_time":"2023-07-01T12:06:45.682889","exception":false,"start_time":"2023-07-01T12:06:45.673012","status":"completed"},"tags":[]},"source":["# <a id=\"4\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >4 - EXPLORATORY DATA ANALYSIS.  <br><div>\n","#### <span style=\"color: #FF4500;\">Exploratory Data Analysis (EDA) is a crucial step in the data analysis process. It involves examining and understanding the dataset to gain insights, discover patterns, and identify potential issues or relationships within the data\n"]},{"cell_type":"markdown","id":"fc57040a","metadata":{"papermill":{"duration":0.009811,"end_time":"2023-07-01T12:06:45.703197","exception":false,"start_time":"2023-07-01T12:06:45.693386","status":"completed"},"tags":[]},"source":["# <a id = \"4.1\"></a>\n","#### <span style=\"color: #FF4500;\">4.1 : EDA OF TRAINING DATA.</span>"]},{"cell_type":"code","execution_count":3,"id":"f1da9489","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.724563Z","iopub.status.busy":"2023-07-01T12:06:45.724236Z","iopub.status.idle":"2023-07-01T12:06:45.75854Z","shell.execute_reply":"2023-07-01T12:06:45.75757Z"},"papermill":{"duration":0.047496,"end_time":"2023-07-01T12:06:45.760588","exception":false,"start_time":"2023-07-01T12:06:45.713092","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-114.31</td>\n","      <td>34.19</td>\n","      <td>15.0</td>\n","      <td>5612.0</td>\n","      <td>1283.0</td>\n","      <td>1015.0</td>\n","      <td>472.0</td>\n","      <td>1.4936</td>\n","      <td>66900.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-114.47</td>\n","      <td>34.40</td>\n","      <td>19.0</td>\n","      <td>7650.0</td>\n","      <td>1901.0</td>\n","      <td>1129.0</td>\n","      <td>463.0</td>\n","      <td>1.8200</td>\n","      <td>80100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-114.56</td>\n","      <td>33.69</td>\n","      <td>17.0</td>\n","      <td>720.0</td>\n","      <td>174.0</td>\n","      <td>333.0</td>\n","      <td>117.0</td>\n","      <td>1.6509</td>\n","      <td>85700.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-114.57</td>\n","      <td>33.64</td>\n","      <td>14.0</td>\n","      <td>1501.0</td>\n","      <td>337.0</td>\n","      <td>515.0</td>\n","      <td>226.0</td>\n","      <td>3.1917</td>\n","      <td>73400.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-114.57</td>\n","      <td>33.57</td>\n","      <td>20.0</td>\n","      <td>1454.0</td>\n","      <td>326.0</td>\n","      <td>624.0</td>\n","      <td>262.0</td>\n","      <td>1.9250</td>\n","      <td>65500.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","0    -114.31     34.19                15.0       5612.0          1283.0   \n","1    -114.47     34.40                19.0       7650.0          1901.0   \n","2    -114.56     33.69                17.0        720.0           174.0   \n","3    -114.57     33.64                14.0       1501.0           337.0   \n","4    -114.57     33.57                20.0       1454.0           326.0   \n","\n","   population  households  median_income  median_house_value  \n","0      1015.0       472.0         1.4936             66900.0  \n","1      1129.0       463.0         1.8200             80100.0  \n","2       333.0       117.0         1.6509             85700.0  \n","3       515.0       226.0         3.1917             73400.0  \n","4       624.0       262.0         1.9250             65500.0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Display the first few rows of the DataFrame\n","train_df.head()\n"]},{"cell_type":"code","execution_count":4,"id":"dcd1833d","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.783265Z","iopub.status.busy":"2023-07-01T12:06:45.782886Z","iopub.status.idle":"2023-07-01T12:06:45.797477Z","shell.execute_reply":"2023-07-01T12:06:45.79632Z"},"papermill":{"duration":0.028187,"end_time":"2023-07-01T12:06:45.799177","exception":false,"start_time":"2023-07-01T12:06:45.77099","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16995</th>\n","      <td>-124.26</td>\n","      <td>40.58</td>\n","      <td>52.0</td>\n","      <td>2217.0</td>\n","      <td>394.0</td>\n","      <td>907.0</td>\n","      <td>369.0</td>\n","      <td>2.3571</td>\n","      <td>111400.0</td>\n","    </tr>\n","    <tr>\n","      <th>16996</th>\n","      <td>-124.27</td>\n","      <td>40.69</td>\n","      <td>36.0</td>\n","      <td>2349.0</td>\n","      <td>528.0</td>\n","      <td>1194.0</td>\n","      <td>465.0</td>\n","      <td>2.5179</td>\n","      <td>79000.0</td>\n","    </tr>\n","    <tr>\n","      <th>16997</th>\n","      <td>-124.30</td>\n","      <td>41.84</td>\n","      <td>17.0</td>\n","      <td>2677.0</td>\n","      <td>531.0</td>\n","      <td>1244.0</td>\n","      <td>456.0</td>\n","      <td>3.0313</td>\n","      <td>103600.0</td>\n","    </tr>\n","    <tr>\n","      <th>16998</th>\n","      <td>-124.30</td>\n","      <td>41.80</td>\n","      <td>19.0</td>\n","      <td>2672.0</td>\n","      <td>552.0</td>\n","      <td>1298.0</td>\n","      <td>478.0</td>\n","      <td>1.9797</td>\n","      <td>85800.0</td>\n","    </tr>\n","    <tr>\n","      <th>16999</th>\n","      <td>-124.35</td>\n","      <td>40.54</td>\n","      <td>52.0</td>\n","      <td>1820.0</td>\n","      <td>300.0</td>\n","      <td>806.0</td>\n","      <td>270.0</td>\n","      <td>3.0147</td>\n","      <td>94600.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","16995    -124.26     40.58                52.0       2217.0           394.0   \n","16996    -124.27     40.69                36.0       2349.0           528.0   \n","16997    -124.30     41.84                17.0       2677.0           531.0   \n","16998    -124.30     41.80                19.0       2672.0           552.0   \n","16999    -124.35     40.54                52.0       1820.0           300.0   \n","\n","       population  households  median_income  median_house_value  \n","16995       907.0       369.0         2.3571            111400.0  \n","16996      1194.0       465.0         2.5179             79000.0  \n","16997      1244.0       456.0         3.0313            103600.0  \n","16998      1298.0       478.0         1.9797             85800.0  \n","16999       806.0       270.0         3.0147             94600.0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Display the last 5 rows of the DataFrame\n","\n","train_df.tail()"]},{"cell_type":"code","execution_count":5,"id":"923aff4d","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.821723Z","iopub.status.busy":"2023-07-01T12:06:45.821393Z","iopub.status.idle":"2023-07-01T12:06:45.827562Z","shell.execute_reply":"2023-07-01T12:06:45.826238Z"},"papermill":{"duration":0.019713,"end_time":"2023-07-01T12:06:45.829482","exception":false,"start_time":"2023-07-01T12:06:45.809769","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The DataFrame of Training data consists of 17000 rows and 9 columns.\n"]}],"source":["# Check the dimensions of the DataFrame (rows, columns)\n","shape = train_df.shape\n","print(\"The DataFrame of Training data consists of {} rows and {} columns.\".format(shape[0], shape[1]))"]},{"cell_type":"code","execution_count":6,"id":"98e67f3e","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.852793Z","iopub.status.busy":"2023-07-01T12:06:45.851935Z","iopub.status.idle":"2023-07-01T12:06:45.898343Z","shell.execute_reply":"2023-07-01T12:06:45.897051Z"},"papermill":{"duration":0.061428,"end_time":"2023-07-01T12:06:45.901638","exception":false,"start_time":"2023-07-01T12:06:45.84021","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","      <td>17000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-119.562108</td>\n","      <td>35.625225</td>\n","      <td>28.589353</td>\n","      <td>2643.664412</td>\n","      <td>539.410824</td>\n","      <td>1429.573941</td>\n","      <td>501.221941</td>\n","      <td>3.883578</td>\n","      <td>207300.912353</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.005166</td>\n","      <td>2.137340</td>\n","      <td>12.586937</td>\n","      <td>2179.947071</td>\n","      <td>421.499452</td>\n","      <td>1147.852959</td>\n","      <td>384.520841</td>\n","      <td>1.908157</td>\n","      <td>115983.764387</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-124.350000</td>\n","      <td>32.540000</td>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>0.499900</td>\n","      <td>14999.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-121.790000</td>\n","      <td>33.930000</td>\n","      <td>18.000000</td>\n","      <td>1462.000000</td>\n","      <td>297.000000</td>\n","      <td>790.000000</td>\n","      <td>282.000000</td>\n","      <td>2.566375</td>\n","      <td>119400.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-118.490000</td>\n","      <td>34.250000</td>\n","      <td>29.000000</td>\n","      <td>2127.000000</td>\n","      <td>434.000000</td>\n","      <td>1167.000000</td>\n","      <td>409.000000</td>\n","      <td>3.544600</td>\n","      <td>180400.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>-118.000000</td>\n","      <td>37.720000</td>\n","      <td>37.000000</td>\n","      <td>3151.250000</td>\n","      <td>648.250000</td>\n","      <td>1721.000000</td>\n","      <td>605.250000</td>\n","      <td>4.767000</td>\n","      <td>265000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>-114.310000</td>\n","      <td>41.950000</td>\n","      <td>52.000000</td>\n","      <td>37937.000000</td>\n","      <td>6445.000000</td>\n","      <td>35682.000000</td>\n","      <td>6082.000000</td>\n","      <td>15.000100</td>\n","      <td>500001.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          longitude      latitude  housing_median_age   total_rooms  \\\n","count  17000.000000  17000.000000        17000.000000  17000.000000   \n","mean    -119.562108     35.625225           28.589353   2643.664412   \n","std        2.005166      2.137340           12.586937   2179.947071   \n","min     -124.350000     32.540000            1.000000      2.000000   \n","25%     -121.790000     33.930000           18.000000   1462.000000   \n","50%     -118.490000     34.250000           29.000000   2127.000000   \n","75%     -118.000000     37.720000           37.000000   3151.250000   \n","max     -114.310000     41.950000           52.000000  37937.000000   \n","\n","       total_bedrooms    population    households  median_income  \\\n","count    17000.000000  17000.000000  17000.000000   17000.000000   \n","mean       539.410824   1429.573941    501.221941       3.883578   \n","std        421.499452   1147.852959    384.520841       1.908157   \n","min          1.000000      3.000000      1.000000       0.499900   \n","25%        297.000000    790.000000    282.000000       2.566375   \n","50%        434.000000   1167.000000    409.000000       3.544600   \n","75%        648.250000   1721.000000    605.250000       4.767000   \n","max       6445.000000  35682.000000   6082.000000      15.000100   \n","\n","       median_house_value  \n","count        17000.000000  \n","mean        207300.912353  \n","std         115983.764387  \n","min          14999.000000  \n","25%         119400.000000  \n","50%         180400.000000  \n","75%         265000.000000  \n","max         500001.000000  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Get summary statistics of the numerical columns\n","train_df.describe()\n"]},{"cell_type":"code","execution_count":7,"id":"b700943e","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.92489Z","iopub.status.busy":"2023-07-01T12:06:45.924522Z","iopub.status.idle":"2023-07-01T12:06:45.931933Z","shell.execute_reply":"2023-07-01T12:06:45.931039Z"},"papermill":{"duration":0.021,"end_time":"2023-07-01T12:06:45.933639","exception":false,"start_time":"2023-07-01T12:06:45.912639","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["longitude             float64\n","latitude              float64\n","housing_median_age    float64\n","total_rooms           float64\n","total_bedrooms        float64\n","population            float64\n","households            float64\n","median_income         float64\n","median_house_value    float64\n","dtype: object"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Check the data types of each column\n","train_df.dtypes\n"]},{"cell_type":"code","execution_count":8,"id":"0d20753f","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:45.956984Z","iopub.status.busy":"2023-07-01T12:06:45.956573Z","iopub.status.idle":"2023-07-01T12:06:45.964752Z","shell.execute_reply":"2023-07-01T12:06:45.96372Z"},"papermill":{"duration":0.022592,"end_time":"2023-07-01T12:06:45.967114","exception":false,"start_time":"2023-07-01T12:06:45.944522","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["longitude             0\n","latitude              0\n","housing_median_age    0\n","total_rooms           0\n","total_bedrooms        0\n","population            0\n","households            0\n","median_income         0\n","median_house_value    0\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Check for missing values in the dataset\n","train_df.isnull().sum()"]},{"cell_type":"markdown","id":"a273e9df","metadata":{"papermill":{"duration":0.01163,"end_time":"2023-07-01T12:06:45.990812","exception":false,"start_time":"2023-07-01T12:06:45.979182","status":"completed"},"tags":[]},"source":["<a id = \"4.2\"></a>\n","#### <span style=\"color: #FF4500;\">4.2 : EDA OF TESTING DATA.</span>"]},{"cell_type":"code","execution_count":9,"id":"7d2aa905","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.016327Z","iopub.status.busy":"2023-07-01T12:06:46.015529Z","iopub.status.idle":"2023-07-01T12:06:46.030521Z","shell.execute_reply":"2023-07-01T12:06:46.029649Z"},"papermill":{"duration":0.029348,"end_time":"2023-07-01T12:06:46.032312","exception":false,"start_time":"2023-07-01T12:06:46.002964","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-122.05</td>\n","      <td>37.37</td>\n","      <td>27.0</td>\n","      <td>3885.0</td>\n","      <td>661.0</td>\n","      <td>1537.0</td>\n","      <td>606.0</td>\n","      <td>6.6085</td>\n","      <td>344700.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-118.30</td>\n","      <td>34.26</td>\n","      <td>43.0</td>\n","      <td>1510.0</td>\n","      <td>310.0</td>\n","      <td>809.0</td>\n","      <td>277.0</td>\n","      <td>3.5990</td>\n","      <td>176500.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-117.81</td>\n","      <td>33.78</td>\n","      <td>27.0</td>\n","      <td>3589.0</td>\n","      <td>507.0</td>\n","      <td>1484.0</td>\n","      <td>495.0</td>\n","      <td>5.7934</td>\n","      <td>270500.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-118.36</td>\n","      <td>33.82</td>\n","      <td>28.0</td>\n","      <td>67.0</td>\n","      <td>15.0</td>\n","      <td>49.0</td>\n","      <td>11.0</td>\n","      <td>6.1359</td>\n","      <td>330000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-119.67</td>\n","      <td>36.33</td>\n","      <td>19.0</td>\n","      <td>1241.0</td>\n","      <td>244.0</td>\n","      <td>850.0</td>\n","      <td>237.0</td>\n","      <td>2.9375</td>\n","      <td>81700.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","0    -122.05     37.37                27.0       3885.0           661.0   \n","1    -118.30     34.26                43.0       1510.0           310.0   \n","2    -117.81     33.78                27.0       3589.0           507.0   \n","3    -118.36     33.82                28.0         67.0            15.0   \n","4    -119.67     36.33                19.0       1241.0           244.0   \n","\n","   population  households  median_income  median_house_value  \n","0      1537.0       606.0         6.6085            344700.0  \n","1       809.0       277.0         3.5990            176500.0  \n","2      1484.0       495.0         5.7934            270500.0  \n","3        49.0        11.0         6.1359            330000.0  \n","4       850.0       237.0         2.9375             81700.0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Display the first few rows of the DataFrame\n","test_df.head()\n"]},{"cell_type":"code","execution_count":10,"id":"d81a4a95","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.0572Z","iopub.status.busy":"2023-07-01T12:06:46.056196Z","iopub.status.idle":"2023-07-01T12:06:46.072548Z","shell.execute_reply":"2023-07-01T12:06:46.071605Z"},"papermill":{"duration":0.030795,"end_time":"2023-07-01T12:06:46.074366","exception":false,"start_time":"2023-07-01T12:06:46.043571","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2995</th>\n","      <td>-119.86</td>\n","      <td>34.42</td>\n","      <td>23.0</td>\n","      <td>1450.0</td>\n","      <td>642.0</td>\n","      <td>1258.0</td>\n","      <td>607.0</td>\n","      <td>1.1790</td>\n","      <td>225000.0</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>-118.14</td>\n","      <td>34.06</td>\n","      <td>27.0</td>\n","      <td>5257.0</td>\n","      <td>1082.0</td>\n","      <td>3496.0</td>\n","      <td>1036.0</td>\n","      <td>3.3906</td>\n","      <td>237200.0</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>-119.70</td>\n","      <td>36.30</td>\n","      <td>10.0</td>\n","      <td>956.0</td>\n","      <td>201.0</td>\n","      <td>693.0</td>\n","      <td>220.0</td>\n","      <td>2.2895</td>\n","      <td>62000.0</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>-117.12</td>\n","      <td>34.10</td>\n","      <td>40.0</td>\n","      <td>96.0</td>\n","      <td>14.0</td>\n","      <td>46.0</td>\n","      <td>14.0</td>\n","      <td>3.2708</td>\n","      <td>162500.0</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>-119.63</td>\n","      <td>34.42</td>\n","      <td>42.0</td>\n","      <td>1765.0</td>\n","      <td>263.0</td>\n","      <td>753.0</td>\n","      <td>260.0</td>\n","      <td>8.5608</td>\n","      <td>500001.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","2995    -119.86     34.42                23.0       1450.0           642.0   \n","2996    -118.14     34.06                27.0       5257.0          1082.0   \n","2997    -119.70     36.30                10.0        956.0           201.0   \n","2998    -117.12     34.10                40.0         96.0            14.0   \n","2999    -119.63     34.42                42.0       1765.0           263.0   \n","\n","      population  households  median_income  median_house_value  \n","2995      1258.0       607.0         1.1790            225000.0  \n","2996      3496.0      1036.0         3.3906            237200.0  \n","2997       693.0       220.0         2.2895             62000.0  \n","2998        46.0        14.0         3.2708            162500.0  \n","2999       753.0       260.0         8.5608            500001.0  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Display the last 5 rows of the DataFrame\n","\n","test_df.tail()"]},{"cell_type":"code","execution_count":11,"id":"73251c2b","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.099025Z","iopub.status.busy":"2023-07-01T12:06:46.098678Z","iopub.status.idle":"2023-07-01T12:06:46.103782Z","shell.execute_reply":"2023-07-01T12:06:46.102775Z"},"papermill":{"duration":0.019747,"end_time":"2023-07-01T12:06:46.105775","exception":false,"start_time":"2023-07-01T12:06:46.086028","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The DataFrame of Testing data consists of 17000 rows and 9 columns.\n"]}],"source":["# Check the dimensions of the DataFrame (rows, columns)\n","shape = train_df.shape\n","print(\"The DataFrame of Testing data consists of {} rows and {} columns.\".format(shape[0], shape[1]))"]},{"cell_type":"code","execution_count":12,"id":"1cf26e9e","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.130782Z","iopub.status.busy":"2023-07-01T12:06:46.129681Z","iopub.status.idle":"2023-07-01T12:06:46.164106Z","shell.execute_reply":"2023-07-01T12:06:46.162928Z"},"papermill":{"duration":0.049029,"end_time":"2023-07-01T12:06:46.166522","exception":false,"start_time":"2023-07-01T12:06:46.117493","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3000.000000</td>\n","      <td>3000.00000</td>\n","      <td>3000.000000</td>\n","      <td>3000.000000</td>\n","      <td>3000.000000</td>\n","      <td>3000.000000</td>\n","      <td>3000.00000</td>\n","      <td>3000.000000</td>\n","      <td>3000.00000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>-119.589200</td>\n","      <td>35.63539</td>\n","      <td>28.845333</td>\n","      <td>2599.578667</td>\n","      <td>529.950667</td>\n","      <td>1402.798667</td>\n","      <td>489.91200</td>\n","      <td>3.807272</td>\n","      <td>205846.27500</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.994936</td>\n","      <td>2.12967</td>\n","      <td>12.555396</td>\n","      <td>2155.593332</td>\n","      <td>415.654368</td>\n","      <td>1030.543012</td>\n","      <td>365.42271</td>\n","      <td>1.854512</td>\n","      <td>113119.68747</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-124.180000</td>\n","      <td>32.56000</td>\n","      <td>1.000000</td>\n","      <td>6.000000</td>\n","      <td>2.000000</td>\n","      <td>5.000000</td>\n","      <td>2.00000</td>\n","      <td>0.499900</td>\n","      <td>22500.00000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-121.810000</td>\n","      <td>33.93000</td>\n","      <td>18.000000</td>\n","      <td>1401.000000</td>\n","      <td>291.000000</td>\n","      <td>780.000000</td>\n","      <td>273.00000</td>\n","      <td>2.544000</td>\n","      <td>121200.00000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-118.485000</td>\n","      <td>34.27000</td>\n","      <td>29.000000</td>\n","      <td>2106.000000</td>\n","      <td>437.000000</td>\n","      <td>1155.000000</td>\n","      <td>409.50000</td>\n","      <td>3.487150</td>\n","      <td>177650.00000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>-118.020000</td>\n","      <td>37.69000</td>\n","      <td>37.000000</td>\n","      <td>3129.000000</td>\n","      <td>636.000000</td>\n","      <td>1742.750000</td>\n","      <td>597.25000</td>\n","      <td>4.656475</td>\n","      <td>263975.00000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>-114.490000</td>\n","      <td>41.92000</td>\n","      <td>52.000000</td>\n","      <td>30450.000000</td>\n","      <td>5419.000000</td>\n","      <td>11935.000000</td>\n","      <td>4930.00000</td>\n","      <td>15.000100</td>\n","      <td>500001.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         longitude    latitude  housing_median_age   total_rooms  \\\n","count  3000.000000  3000.00000         3000.000000   3000.000000   \n","mean   -119.589200    35.63539           28.845333   2599.578667   \n","std       1.994936     2.12967           12.555396   2155.593332   \n","min    -124.180000    32.56000            1.000000      6.000000   \n","25%    -121.810000    33.93000           18.000000   1401.000000   \n","50%    -118.485000    34.27000           29.000000   2106.000000   \n","75%    -118.020000    37.69000           37.000000   3129.000000   \n","max    -114.490000    41.92000           52.000000  30450.000000   \n","\n","       total_bedrooms    population  households  median_income  \\\n","count     3000.000000   3000.000000  3000.00000    3000.000000   \n","mean       529.950667   1402.798667   489.91200       3.807272   \n","std        415.654368   1030.543012   365.42271       1.854512   \n","min          2.000000      5.000000     2.00000       0.499900   \n","25%        291.000000    780.000000   273.00000       2.544000   \n","50%        437.000000   1155.000000   409.50000       3.487150   \n","75%        636.000000   1742.750000   597.25000       4.656475   \n","max       5419.000000  11935.000000  4930.00000      15.000100   \n","\n","       median_house_value  \n","count          3000.00000  \n","mean         205846.27500  \n","std          113119.68747  \n","min           22500.00000  \n","25%          121200.00000  \n","50%          177650.00000  \n","75%          263975.00000  \n","max          500001.00000  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Get summary statistics of the numerical columns\n","test_df.describe()\n"]},{"cell_type":"code","execution_count":13,"id":"46953f63","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.193067Z","iopub.status.busy":"2023-07-01T12:06:46.191688Z","iopub.status.idle":"2023-07-01T12:06:46.200755Z","shell.execute_reply":"2023-07-01T12:06:46.199332Z"},"papermill":{"duration":0.024664,"end_time":"2023-07-01T12:06:46.203056","exception":false,"start_time":"2023-07-01T12:06:46.178392","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["longitude             float64\n","latitude              float64\n","housing_median_age    float64\n","total_rooms           float64\n","total_bedrooms        float64\n","population            float64\n","households            float64\n","median_income         float64\n","median_house_value    float64\n","dtype: object"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Check the data types of each column\n","test_df.dtypes"]},{"cell_type":"code","execution_count":14,"id":"08181d2e","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.229632Z","iopub.status.busy":"2023-07-01T12:06:46.229025Z","iopub.status.idle":"2023-07-01T12:06:46.236143Z","shell.execute_reply":"2023-07-01T12:06:46.235112Z"},"papermill":{"duration":0.023177,"end_time":"2023-07-01T12:06:46.23834","exception":false,"start_time":"2023-07-01T12:06:46.215163","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["longitude             float64\n","latitude              float64\n","housing_median_age    float64\n","total_rooms           float64\n","total_bedrooms        float64\n","population            float64\n","households            float64\n","median_income         float64\n","median_house_value    float64\n","dtype: object"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Check the data types of each column\n","test_df.dtypes"]},{"cell_type":"markdown","id":"a7b5cd1a","metadata":{"papermill":{"duration":0.01142,"end_time":"2023-07-01T12:06:46.261911","exception":false,"start_time":"2023-07-01T12:06:46.250491","status":"completed"},"tags":[]},"source":["<a id = \"4.3\"></a>\n","#### <span style=\"color: #FF4500;\">4.3 : CONVERTING THIS DATA INTO NUMPY MATRICES.</span>"]},{"cell_type":"code","execution_count":15,"id":"7d3465a8","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.287554Z","iopub.status.busy":"2023-07-01T12:06:46.286936Z","iopub.status.idle":"2023-07-01T12:06:46.292565Z","shell.execute_reply":"2023-07-01T12:06:46.291591Z"},"papermill":{"duration":0.020481,"end_time":"2023-07-01T12:06:46.294326","exception":false,"start_time":"2023-07-01T12:06:46.273845","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of the new matrices are for X_train = (17000, 8) and for Y_train = (17000,)\n"]}],"source":["X_train,Y_train = train_df.to_numpy()[:,:-1],train_df.to_numpy()[:,-1]\n","\n","print(\"The shape of the new matrices are for X_train = {} and for Y_train = {}\".format(X_train.shape , Y_train.shape)) "]},{"cell_type":"code","execution_count":16,"id":"839814ff","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.320337Z","iopub.status.busy":"2023-07-01T12:06:46.319806Z","iopub.status.idle":"2023-07-01T12:06:46.325142Z","shell.execute_reply":"2023-07-01T12:06:46.324162Z"},"papermill":{"duration":0.02037,"end_time":"2023-07-01T12:06:46.326777","exception":false,"start_time":"2023-07-01T12:06:46.306407","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of the new matrices are for X_train = (3000, 8) and for Y_train = (3000,)\n"]}],"source":["X_test,Y_test = test_df.to_numpy()[:,:-1],test_df.to_numpy()[:,-1]\n","print(\"The shape of the new matrices are for X_train = {} and for Y_train = {}\".format(X_test.shape , Y_test.shape)) "]},{"cell_type":"markdown","id":"f997aeec","metadata":{"papermill":{"duration":0.011539,"end_time":"2023-07-01T12:06:46.350277","exception":false,"start_time":"2023-07-01T12:06:46.338738","status":"completed"},"tags":[]},"source":["<a id = \"4.4\"></a>\n","#### <span style=\"color: #FF4500;\"> 4.4) SCALING THE VALUES </span>\n","\n","1.) **StandardScaler** : \n","StandardScaler is a data preprocessing technique commonly used in machine learning and statistics. It is used to standardize features or variables by transforming them to have zero mean and unit variance.\n","\n","\n","2.) **MinMaxScaler** : \n","MinMaxScaler is another data preprocessing technique commonly used in machine learning. It transforms features or variables by scaling them to a specific range, typically between 0 and 1. \n","\n","\n","3.) **FunctionTransformer** :The FunctionTransformer is a class in scikit-learn that allows you to apply custom transformations to your data using a specified function. It is particularly useful when you want to apply a transformation that is not available as a built-in transformer in scikit-learn.\n","\n","The FunctionTransformer class takes two important parameters:\n","\n","*func:* \n","This parameter expects a callable function that defines the transformation to be applied to the data.\n","\n","*validate:* \n","This parameter controls whether the input data should be validated before applying the transformation.\n"]},{"cell_type":"code","execution_count":17,"id":"b4ca65f4","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.376224Z","iopub.status.busy":"2023-07-01T12:06:46.375651Z","iopub.status.idle":"2023-07-01T12:06:46.417707Z","shell.execute_reply":"2023-07-01T12:06:46.416424Z"},"papermill":{"duration":0.057658,"end_time":"2023-07-01T12:06:46.419866","exception":false,"start_time":"2023-07-01T12:06:46.362208","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler , MinMaxScaler , FunctionTransformer \n","from copy import deepcopy"]},{"cell_type":"code","execution_count":18,"id":"c03507ca","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.445657Z","iopub.status.busy":"2023-07-01T12:06:46.445327Z","iopub.status.idle":"2023-07-01T12:06:46.453119Z","shell.execute_reply":"2023-07-01T12:06:46.451819Z"},"papermill":{"duration":0.02298,"end_time":"2023-07-01T12:06:46.454965","exception":false,"start_time":"2023-07-01T12:06:46.431985","status":"completed"},"tags":[]},"outputs":[],"source":["# Copying only first two columns i.e the Longitude and Latitude after scaling :\n","std_scaler = StandardScaler().fit(X_train[:, :2])\n","\n","# Copying all columns besides the first two :\n","min_max_scaler = MinMaxScaler().fit(X_train[: , 2:])\n","\n","# a preprocessor function that performs a preprocessing operation on a numpy array X\n","def preprocessor(X):\n","    A = np.copy(X)\n","    A[: , :2] = std_scaler.transform(X[:,:2])\n","    A[:,  2:] = min_max_scaler.transform(X[ : , 2: ])\n","    return A"]},{"cell_type":"markdown","id":"c37a6e9d","metadata":{"papermill":{"duration":0.011587,"end_time":"2023-07-01T12:06:46.478595","exception":false,"start_time":"2023-07-01T12:06:46.467008","status":"completed"},"tags":[]},"source":["### <span style=\"color: #FF4500;\"> VERIFYING THE WORKING OF THE FUNCTION. </span>"]},{"cell_type":"code","execution_count":19,"id":"af767318","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.504227Z","iopub.status.busy":"2023-07-01T12:06:46.503875Z","iopub.status.idle":"2023-07-01T12:06:46.511409Z","shell.execute_reply":"2023-07-01T12:06:46.510677Z"},"papermill":{"duration":0.022837,"end_time":"2023-07-01T12:06:46.513468","exception":false,"start_time":"2023-07-01T12:06:46.490631","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([[-1.24077729e+00,  8.16354338e-01,  5.09803922e-01, ...,\n","         4.29944785e-02,  9.94902154e-02,  4.21276948e-01],\n","       [ 6.29446690e-01, -6.38768279e-01,  8.23529412e-01, ...,\n","         2.25903192e-02,  4.53872718e-02,  2.13728087e-01],\n","       [ 8.73822623e-01, -8.63353120e-01,  5.09803922e-01, ...,\n","         4.15090109e-02,  8.12366387e-02,  3.65063930e-01],\n","       ...,\n","       [-6.87702626e-02,  3.15717296e-01,  1.76470588e-01, ...,\n","         1.93391070e-02,  3.60138135e-02,  1.23418987e-01],\n","       [ 1.21794383e+00, -7.13629892e-01,  7.64705882e-01, ...,\n","         1.20519073e-03,  2.13780628e-03,  1.91093916e-01],\n","       [-3.38594150e-02, -5.63906665e-01,  8.03921569e-01, ...,\n","         2.10207685e-02,  4.25916790e-02,  5.55916470e-01]])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["preprocessor(X_test)"]},{"cell_type":"markdown","id":"4afe5aff","metadata":{"papermill":{"duration":0.011952,"end_time":"2023-07-01T12:06:46.537757","exception":false,"start_time":"2023-07-01T12:06:46.525805","status":"completed"},"tags":[]},"source":["### <span style=\"color: #FF4500;\"> USING FUNCTION TRANSFORMER TO HAVE OUR OWN CUSTOM INPUT.</span>"]},{"cell_type":"code","execution_count":20,"id":"721970f4","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.565148Z","iopub.status.busy":"2023-07-01T12:06:46.564679Z","iopub.status.idle":"2023-07-01T12:06:46.571407Z","shell.execute_reply":"2023-07-01T12:06:46.570271Z"},"papermill":{"duration":0.023118,"end_time":"2023-07-01T12:06:46.573459","exception":false,"start_time":"2023-07-01T12:06:46.550341","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<function __main__.preprocessor(X)>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["preprocess_transformers = FunctionTransformer(preprocessor)\n","preprocessor"]},{"cell_type":"markdown","id":"6f9f27cb","metadata":{"papermill":{"duration":0.012213,"end_time":"2023-07-01T12:06:46.598179","exception":false,"start_time":"2023-07-01T12:06:46.585966","status":"completed"},"tags":[]},"source":["\n","# <a id=\"5\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >5 - MODEL BUILDING<br><div>\n","\n","#### <span style=\"color: #FF4500;\"> This is one of the most essential and also a crucial part known as model building we have a lot of models ,However;based on the problem at given hand we are meant to select a model that provides the most optimal soultion to it with minimal error rate in both the Training as well as the Testing data . It is generally followed after cleaning the data in EDA process . Here we will be constructing three different models to check which one fits the data we are using very well .  They are as follows.\n","    "]},{"cell_type":"markdown","id":"90d2592f","metadata":{"papermill":{"duration":0.012106,"end_time":"2023-07-01T12:06:46.62306","exception":false,"start_time":"2023-07-01T12:06:46.610954","status":"completed"},"tags":[]},"source":["\n","<a id = \"5.1\"></a>\n","## <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >5.1 -  LINEAR REGRESSION MODEL :<br><div>\n","    \n","### <span style=\"color: #FF4500;\">Linear regression is a statistical modeling technique used to analyze the relationship between a dependent variable and one or more independent variables. It aims to find the best-fitting linear relationship between the input variables and the output variable.In the context of machine learning, linear regression is often used as a predictive model to estimate or predict the value of a continuous target variable based on input features. The model assumes that there is a linear relationship between the independent variables (features) and the dependent variable (target).Linear regression can be extended to handle more complex relationships by including polynomial features or by using techniques such as regularization (e.g., Ridge regression or Lasso regression) to prevent overfitting.\n","\n"]},{"cell_type":"code","execution_count":21,"id":"ac292093","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.650312Z","iopub.status.busy":"2023-07-01T12:06:46.649959Z","iopub.status.idle":"2023-07-01T12:06:46.889993Z","shell.execute_reply":"2023-07-01T12:06:46.88825Z"},"papermill":{"duration":0.256714,"end_time":"2023-07-01T12:06:46.892617","exception":false,"start_time":"2023-07-01T12:06:46.635903","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","id":"17f3d25e","metadata":{"papermill":{"duration":0.012494,"end_time":"2023-07-01T12:06:46.918645","exception":false,"start_time":"2023-07-01T12:06:46.906151","status":"completed"},"tags":[]},"source":["#### <span style=\"color: #FF4500;\"> CREATING PIPELINES. </span>\n","\n","\n","## *In data science, a pipeline refers to a sequence of data processing steps that are chained together to form a cohesive workflow. It allows for the efficient and automated execution of various tasks involved in data analysis and model development.*\n","\n"]},{"cell_type":"code","execution_count":22,"id":"4a115781","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:46.945533Z","iopub.status.busy":"2023-07-01T12:06:46.945185Z","iopub.status.idle":"2023-07-01T12:06:46.949551Z","shell.execute_reply":"2023-07-01T12:06:46.948592Z"},"papermill":{"duration":0.02077,"end_time":"2023-07-01T12:06:46.952083","exception":false,"start_time":"2023-07-01T12:06:46.931313","status":"completed"},"tags":[]},"outputs":[],"source":["p1 = Pipeline([('Scalar',preprocess_transformers),('Linear Regression',LinearRegression())])\n","\n","# In the above line of the code you can see we have passed the steps in form of Tuples in our Pipeline."]},{"cell_type":"markdown","id":"a60306db","metadata":{"papermill":{"duration":0.012089,"end_time":"2023-07-01T12:06:46.977032","exception":false,"start_time":"2023-07-01T12:06:46.964943","status":"completed"},"tags":[]},"source":["# <A ID = \"5.1.1\"></A>\n","#### <span style=\"color: #FF4500;\"> OUTPUT FOR THE PIPELINE.</span>\n"]},{"cell_type":"code","execution_count":23,"id":"4c076799","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-01T12:06:47.003631Z","iopub.status.busy":"2023-07-01T12:06:47.003282Z","iopub.status.idle":"2023-07-01T12:06:47.014409Z","shell.execute_reply":"2023-07-01T12:06:47.013158Z"},"papermill":{"duration":0.026378,"end_time":"2023-07-01T12:06:47.01611","exception":false,"start_time":"2023-07-01T12:06:46.989732","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Pipeline(steps=[('Scalar',\n","                 FunctionTransformer(func=<function preprocessor at 0x7a38a542f490>)),\n","                ('Linear Regression', LinearRegression())])\n"]}],"source":["print(p1)"]},{"cell_type":"markdown","id":"1945d470","metadata":{"papermill":{"duration":0.012328,"end_time":"2023-07-01T12:06:47.04091","exception":false,"start_time":"2023-07-01T12:06:47.028582","status":"completed"},"tags":[]},"source":["<A ID = \"5.1.2\"></A>\n","#### <span style=\"color: #FF4500;\"> CHECKING ERRORS USING MEAN ABSOLUTE ERROR : . </span>\n"]},{"cell_type":"code","execution_count":24,"id":"270a45f3","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:47.069368Z","iopub.status.busy":"2023-07-01T12:06:47.069031Z","iopub.status.idle":"2023-07-01T12:06:47.07341Z","shell.execute_reply":"2023-07-01T12:06:47.072538Z"},"papermill":{"duration":0.022341,"end_time":"2023-07-01T12:06:47.075819","exception":false,"start_time":"2023-07-01T12:06:47.053478","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error "]},{"cell_type":"markdown","id":"ce74db10","metadata":{"papermill":{"duration":0.012331,"end_time":"2023-07-01T12:06:47.101042","exception":false,"start_time":"2023-07-01T12:06:47.088711","status":"completed"},"tags":[]},"source":["<A ID = \"5.1.3\"></A>\n","### <span style=\"color: #FF4500;\"> Now lets define a function such that it can be used to fit data into pipeline </span>\n","\n"]},{"cell_type":"code","execution_count":25,"id":"7a613772","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:47.12756Z","iopub.status.busy":"2023-07-01T12:06:47.127215Z","iopub.status.idle":"2023-07-01T12:06:47.132504Z","shell.execute_reply":"2023-07-01T12:06:47.131641Z"},"papermill":{"duration":0.020622,"end_time":"2023-07-01T12:06:47.134291","exception":false,"start_time":"2023-07-01T12:06:47.113669","status":"completed"},"tags":[]},"outputs":[],"source":["def fit_and_prnt(p , X_train=X_train , Y_train = Y_train , X_test = X_test , Y_test = Y_test):\n","    #fitting the pipeline :\n","    p.fit(X_train , Y_train)\n","    train_preds = p.predict(X_train)\n","    test_preds = p.predict(X_test)\n","    print( \"Training error : \" + str(mean_absolute_error(train_preds , Y_train)))\n","    print( \"Testing error : \" + str(mean_absolute_error(test_preds , Y_test)))\n"]},{"cell_type":"markdown","id":"f73d833c","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.012274,"end_time":"2023-07-01T12:06:47.159594","exception":false,"start_time":"2023-07-01T12:06:47.14732","status":"completed"},"tags":[]},"source":["# <a id=\"6\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >6 - PREDICTION\n"," <br><div>\n","    "]},{"cell_type":"code","execution_count":26,"id":"b9e272cd","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-01T12:06:47.185978Z","iopub.status.busy":"2023-07-01T12:06:47.185621Z","iopub.status.idle":"2023-07-01T12:06:47.227386Z","shell.execute_reply":"2023-07-01T12:06:47.22655Z"},"papermill":{"duration":0.05769,"end_time":"2023-07-01T12:06:47.229652","exception":false,"start_time":"2023-07-01T12:06:47.171962","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Training error : 50795.857117863714\n","Testing error : 50352.228257942894\n"]}],"source":["fit_and_prnt(p1)"]},{"cell_type":"markdown","id":"eb2b5a43","metadata":{"papermill":{"duration":0.015703,"end_time":"2023-07-01T12:06:47.261115","exception":false,"start_time":"2023-07-01T12:06:47.245412","status":"completed"},"tags":[]},"source":["\n","<p style=\"padding: 10px; background-color: #000000; margin: 0; color: #FF4500; font-family: New Times Roman; font-size: 135%; text-align: center; border-radius: 5px; overflow: hidden; font-weight: 500;\">\n","                    LINEAR REGRESSION MODEL:<br>\n","    As it can be seen here the Training and testing error we got for linear model is :\n","        \n","        Training error : 50795.857117863714\n","        Testing error : 50352.228257942894\n","</p>\n","\n","<p style=\"text-align: center;\">\n","    \n","</p>\n","\n"]},{"cell_type":"markdown","id":"b960a0de","metadata":{"papermill":{"duration":0.016348,"end_time":"2023-07-01T12:06:47.2937","exception":false,"start_time":"2023-07-01T12:06:47.277352","status":"completed"},"tags":[]},"source":["\n","# <a id=\"7\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >7 - EVALUATION <br><div>\n","    \n","\n","<p style=\"text-align: center;\">\n","    \n","<span style=\"color: #FF4500;\"> Here are some general guidelines for interpreting the training and testing errors:\n","\n","**Training Error**: The training error represents how well the model fits the training data. In your case, the training error is approximately 50795.86. A lower training error indicates that the model is able to capture the patterns and relationships in the training data more accurately. However, an extremely low training error might indicate overfitting, where the model has memorized the training data instead of learning generalizable patterns.\n","\n","**Testing Error**: The testing error represents how well the model performs on unseen data, i.e., the testing set. In your case, the testing error is approximately 50352.23. The testing error is typically higher than the training error because the model encounters new data during testing. The goal is to have a testing error that is close to the training error, indicating that the model can generalize well to unseen data.\n","\n","To assess the performance of your model, you can compare the testing error with other models or with a predefined threshold that determines what is an acceptable level of error for your specific problem. Additionally, you can use other evaluation metrics such as R-squared, mean absolute error (MAE), or domain-specific metrics to get a more comprehensive understanding of the model's performance.\n","\n","Keep in mind that the evaluation of a model is highly dependent on the specific problem, dataset, and domain knowledge. It's always recommended to analyze the results in context and consider the trade-offs between different evaluation metrics and requirements.: .</span>\n"]},{"cell_type":"markdown","id":"b4bf5885","metadata":{"papermill":{"duration":0.015556,"end_time":"2023-07-01T12:06:47.325387","exception":false,"start_time":"2023-07-01T12:06:47.309831","status":"completed"},"tags":[]},"source":["## <span style=\"color: #FF4500;\"> Since the Error rate in Training and Testing data was too high we will try changing the model , lets import KNN and look how it will be working.</span>\n"]},{"cell_type":"markdown","id":"a6ce4bc4","metadata":{"papermill":{"duration":0.012645,"end_time":"2023-07-01T12:06:47.354072","exception":false,"start_time":"2023-07-01T12:06:47.341427","status":"completed"},"tags":[]},"source":["# <a id=\"5.2\"></a>\n","## <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >5.2 - KNN MODEL {K - NEAREST NEIGHBOUR}  <br><div>\n","    \n"]},{"cell_type":"markdown","id":"40958bae","metadata":{"papermill":{"duration":0.012383,"end_time":"2023-07-01T12:06:47.379136","exception":false,"start_time":"2023-07-01T12:06:47.366753","status":"completed"},"tags":[]},"source":["\n","<p style=\"padding: 10px; background-color: #000000; margin: 0; color: #FF4500; font-family: New Times Roman; font-size: 135%; text-align: center; border-radius: 5px; overflow: hidden; font-weight: 500;\">\n","                    NOTE :<br>\n","    STEPS 1 - 6 (DATA COLLECTION , DATA PREPROCESSING AND EDA) IF NOT REPEATED WILL NOT MATTER SINCE WE HAVE ALREADY CLEANED THE DATA ACCORDING TO OUR USE . SO WE WILL BE DIRECTLY HOPPING TO \"MODEL BUILIDNG\"</p>\n","\n","<p style=\"text-align: center;\">\n","    \n","</p>\n","\n"]},{"cell_type":"code","execution_count":27,"id":"1315176b","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:47.405353Z","iopub.status.busy":"2023-07-01T12:06:47.40504Z","iopub.status.idle":"2023-07-01T12:06:47.756466Z","shell.execute_reply":"2023-07-01T12:06:47.755517Z"},"papermill":{"duration":0.367095,"end_time":"2023-07-01T12:06:47.75881","exception":false,"start_time":"2023-07-01T12:06:47.391715","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Training error : 28343.652870588237\n","Testing error : 36045.85766666666\n"]}],"source":["from sklearn.neighbors import KNeighborsRegressor as KNR\n","\n","\n","# Using a second pipeline with the same scaling method but choosing KNN regression instead of Linear regression: \n","# Also defining the no. of neighbors as \"5\"\n","p2 = Pipeline([('Scalar',preprocess_transformers),(\"KNN Regression\",KNR(n_neighbors = 5))])\n","fit_and_prnt(p2)"]},{"cell_type":"code","execution_count":28,"id":"920d56fc","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-01T12:06:47.787054Z","iopub.status.busy":"2023-07-01T12:06:47.786638Z","iopub.status.idle":"2023-07-01T12:06:47.795182Z","shell.execute_reply":"2023-07-01T12:06:47.793459Z"},"papermill":{"duration":0.024858,"end_time":"2023-07-01T12:06:47.797217","exception":false,"start_time":"2023-07-01T12:06:47.772359","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Pipeline(steps=[('Scalar',\n","                 FunctionTransformer(func=<function preprocessor at 0x7a38a542f490>)),\n","                ('KNN Regression', KNeighborsRegressor())])\n"]}],"source":["print(p2)"]},{"cell_type":"markdown","id":"57c10e59","metadata":{"papermill":{"duration":0.012781,"end_time":"2023-07-01T12:06:47.823201","exception":false,"start_time":"2023-07-01T12:06:47.81042","status":"completed"},"tags":[]},"source":["\n","<p style=\"padding: 10px; background-color: #000000; margin: 0; color: #FF4500; font-family: New Times Roman; font-size: 135%; text-align: center; border-radius: 5px; overflow: hidden; font-weight: 500;\">\n","                    KNN MODEL:<br>\n","    As it can be seen here the Training and testing error we got for KNN model is :\n","        \n","        Training error : 28343.652870588237\n","        Testing error : 36045.85766666666\n","</p>\n","\n","<p style=\"text-align: center;\">\n","    \n","</p>\n","\n"]},{"cell_type":"markdown","id":"8a426dc5","metadata":{"papermill":{"duration":0.01298,"end_time":"2023-07-01T12:06:47.849256","exception":false,"start_time":"2023-07-01T12:06:47.836276","status":"completed"},"tags":[]},"source":["# <a id=\"6.2\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >6.2 - KNN MODEL EVALUATION  <br><div>\n","    \n","\n","    \n","<span style=\"color: #FF4500;\">It's important to interpret these errors within the context of your problem and domain knowledge. Evaluating the model's performance involves considering the trade-offs between different evaluation metrics and the specific requirements of your application.\n","\n","Training Error: The training error is approximately 28343.65. This indicates how well the model fits the training data. A lower training error suggests that the model is able to capture the patterns and relationships in the training data more accurately.\n","\n","Testing Error: The testing error is approximately 36045.86. This represents how well the model performs on unseen data, i.e., the testing set. The testing error is typically higher than the training error since the model encounters new data during testing. The goal is to have a testing error that is close to the training error, indicating that the model can generalize well to unseen data. .</span>\n"]},{"cell_type":"markdown","id":"af892e9e","metadata":{"papermill":{"duration":0.012972,"end_time":"2023-07-01T12:06:47.875483","exception":false,"start_time":"2023-07-01T12:06:47.862511","status":"completed"},"tags":[]},"source":["# <a id=\"5.3\"></a>\n","## <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >5.3 - RANDOM FOREST REGRESSION.  <br><div>\n","### <span style=\"color: #FF4500;\">RFR stands for Random Forest Regression, which is a supervised machine learning algorithm used for regression tasks. It is an extension of the Random Forest algorithm, which is primarily used for classification.Random Forest Regression combines the concept of ensemble learning with decision tree models to make predictions. It creates an ensemble of multiple decision trees and averages their predictions to obtain a final prediction. Each decision tree is constructed using a randomly selected subset of the training data and a subset of input features, providing diversity and reducing overfitting.Random Forest Regression offers several advantages, including:</span>\n","    \n","* It can handle a large number of input features and works well with high-dimensional data.\n","* It reduces overfitting by combining predictions from multiple trees.\n","* It provides an estimate of feature importance, allowing for feature selection.\n","* It can capture non-linear relationships between features and target variables.\n","    \n","    \n","### <span style=\"color: #FF4500;\">However, Random Forest Regression also has some limitations, such as:</span>\n","\n","* It can be computationally expensive, especially when dealing with a large number of trees or complex datasets.\n","* It may not perform well when there are strong linear relationships between features and target variables.\n","\n","### <span style=\"color: #FF4500;\">Overall, Random Forest Regression is a powerful algorithm that is widely used in regression tasks, particularly when dealing with complex and non-linear relationships</span>\n","\n","\n"]},{"cell_type":"code","execution_count":29,"id":"d8635505","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:47.903562Z","iopub.status.busy":"2023-07-01T12:06:47.903006Z","iopub.status.idle":"2023-07-01T12:06:48.609275Z","shell.execute_reply":"2023-07-01T12:06:48.607749Z"},"papermill":{"duration":0.72301,"end_time":"2023-07-01T12:06:48.611371","exception":false,"start_time":"2023-07-01T12:06:47.888361","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Training error : 41458.22567204842\n","Testing error : 44528.65159101441\n"]}],"source":["from sklearn.ensemble import RandomForestRegressor as RFR\n","\n","\n","# Using a second pipeline with the same scaling method but choosing Random forest regression instead of KNN: \n","# Also defining the no. of estimators  as \"10\" and depth as \"5\"\n","p3 = Pipeline([('Scalar',preprocess_transformers),(\"Random Forest\",RFR(n_estimators = 10 , max_depth = 7))])\n","fit_and_prnt(p3)\n"]},{"cell_type":"code","execution_count":30,"id":"2e349872","metadata":{"execution":{"iopub.execute_input":"2023-07-01T12:06:48.638723Z","iopub.status.busy":"2023-07-01T12:06:48.638152Z","iopub.status.idle":"2023-07-01T12:06:48.645833Z","shell.execute_reply":"2023-07-01T12:06:48.645009Z"},"papermill":{"duration":0.0235,"end_time":"2023-07-01T12:06:48.647639","exception":false,"start_time":"2023-07-01T12:06:48.624139","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Pipeline(steps=[('Scalar',\n","                 FunctionTransformer(func=<function preprocessor at 0x7a38a542f490>)),\n","                ('Random Forest',\n","                 RandomForestRegressor(max_depth=7, n_estimators=10))])\n"]}],"source":["print(p3)"]},{"cell_type":"markdown","id":"56c616ac","metadata":{"papermill":{"duration":0.012613,"end_time":"2023-07-01T12:06:48.673087","exception":false,"start_time":"2023-07-01T12:06:48.660474","status":"completed"},"tags":[]},"source":["# <a id=\"5.3.1\"></a>\n","#### <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" >RFR model prediction.  <br><div>\n","    As it can be seen here the Training and testing error we got for RFR model is :\n","        \n","          Training error : 41583.216967626926\n","          Testing error : 44229.32230923467\n"]},{"cell_type":"markdown","id":"78cab542","metadata":{"papermill":{"duration":0.012626,"end_time":"2023-07-01T12:06:48.699442","exception":false,"start_time":"2023-07-01T12:06:48.686816","status":"completed"},"tags":[]},"source":["# <a id=\"8\"></a>\n","## <div style= \"font-family: Times New Roman; font-weight:bold; letter-spacing: 0px; color:WHITE; font-size:120%; text-align:left;padding:3.0px; background: brown; border-bottom: 8px solid WHITE\" > 8 - CONCLUSION  <br><div>\n","    \n","\n","<p style=\"text-align: center;\">\n"," \n","# <span style=\"color: #FF4500;\"> THE ERROR RATE IN ALL THREE ABOVE MODELS WHEN COMPARED GIVES :\n","    \n","    \n","    1.) As it can be seen here the Training and testing error we got for linear model is :\n","        Training error : 50795.857117863714\n","        Testing error : 50352.228257942894\n","  \n","    \n","    2.) As it can be seen here the Training and testing error we got for KNN model is :\n","        Training error : 28343.652870588237\n","        Testing error : 36045.85766666666\n","    \n","    \n","    3.) As it can be seen here the Training and testing error we got for RFR model is :\n","          Training error : 41583.216967626926\n","          Testing error : 44229.32230923467\n"," </span>\n"]},{"cell_type":"markdown","id":"c6e93b36","metadata":{"papermill":{"duration":0.012377,"end_time":"2023-07-01T12:06:48.724671","exception":false,"start_time":"2023-07-01T12:06:48.712294","status":"completed"},"tags":[]},"source":["\n","\n","<span style=\"color: #FF4500;\"> FROM THE CODE IT CAN BE CONCLUDED THAT KNN HAS LOWEST ERROR RATE IN TERMS OF TRAINING DATASET AS WELL AS TESTING DATASET . \n"," .</span>\n"]},{"cell_type":"markdown","id":"dd0006cf","metadata":{"papermill":{"duration":0.01268,"end_time":"2023-07-01T12:06:48.75033","exception":false,"start_time":"2023-07-01T12:06:48.73765","status":"completed"},"tags":[]},"source":["\n","![Alt Text](https://cdn.dribbble.com/users/448124/screenshots/2177658/qq-.gif)\n","# <span style=\"color: skyblue;\"> \"Thank you for checking out my notebook! If you found it helpful, an upvote would be greatly appreciated.As It helps my work to reach furthermore and spread the notebook more deeply and widely in the community that may help a lot of people to learn about skLearn znd the models I have worked on this project . Happy coding!\" . \n"," .</span>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":16.320261,"end_time":"2023-07-01T12:06:49.684741","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-01T12:06:33.36448","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}